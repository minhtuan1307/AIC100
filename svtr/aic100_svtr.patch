diff --git a/ppocr/modeling/backbones/rec_svtrnet.py b/ppocr/modeling/backbones/rec_svtrnet.py
index ea865a2d..1d41355e 100644
--- a/ppocr/modeling/backbones/rec_svtrnet.py
+++ b/ppocr/modeling/backbones/rec_svtrnet.py
@@ -523,20 +523,21 @@ class SVTRNet(nn.Layer):
                 stride=1,
                 padding=0,
                 bias_attr=False)
-            self.hardswish = nn.Hardswish()
+            # self.hardswish = nn.Hardswish()
             self.dropout = nn.Dropout(p=last_drop, mode="downscale_in_infer")
         if not prenorm:
             self.norm = eval(norm_layer)(embed_dim[-1], epsilon=epsilon)
         self.use_lenhead = use_lenhead
         if use_lenhead:
             self.len_conv = nn.Linear(embed_dim[2], self.out_channels)
-            self.hardswish_len = nn.Hardswish()
+            # self.hardswish_len = nn.Hardswish()
             self.dropout_len = nn.Dropout(
                 p=last_drop, mode="downscale_in_infer")
 
         trunc_normal_(self.pos_embed)
         self.apply(self._init_weights)
-
+    def hardswish_alter(self,x):
+        return x*paddle.clip(x+3, 0, 6)/6
     def _init_weights(self, m):
         if isinstance(m, nn.Linear):
             trunc_normal_(m.weight)
@@ -572,7 +573,7 @@ class SVTRNet(nn.Layer):
         x = self.forward_features(x)
         if self.use_lenhead:
             len_x = self.len_conv(x.mean(1))
-            len_x = self.dropout_len(self.hardswish_len(len_x))
+            len_x = self.dropout_len(self.hardswish_alter(len_x))
         if self.last_stage:
             if self.patch_merging is not None:
                 h = self.HW[0] // 4
@@ -582,7 +583,7 @@ class SVTRNet(nn.Layer):
                 x.transpose([0, 2, 1]).reshape(
                     [0, self.embed_dim[2], h, self.HW[1]]))
             x = self.last_conv(x)
-            x = self.hardswish(x)
+            x = self.hardswish_alter(x)
             x = self.dropout(x)
         if self.use_lenhead:
             return x, len_x
diff --git a/ppocr/modeling/transforms/tps_spatial_transformer.py b/ppocr/modeling/transforms/tps_spatial_transformer.py
index 35b1d8bf..46d34ad8 100644
--- a/ppocr/modeling/transforms/tps_spatial_transformer.py
+++ b/ppocr/modeling/transforms/tps_spatial_transformer.py
@@ -26,6 +26,65 @@ from paddle.nn import functional as F
 import numpy as np
 import itertools
 
+def bilinear_grid_sample(im, grid, align_corners = False):
+
+    n, c, h, w = im.shape
+    gn, gh, gw, _ = grid.shape
+    assert n == gn
+
+    x = grid[:, :, :, 0]
+    y = grid[:, :, :, 1]
+
+    if align_corners:
+        x = ((x + 1) / 2) * (w - 1)
+        y = ((y + 1) / 2) * (h - 1)
+    else:
+        x = ((x + 1) * w - 1) / 2
+        y = ((y + 1) * h - 1) / 2
+
+    x = paddle.reshape(x, [n, -1])
+    y = paddle.reshape(x, [n, -1])
+
+    x0 = paddle.cast(paddle.floor(x), "int64")
+    y0 = paddle.cast(paddle.floor(y), "int64")
+    x1 = x0 + 1
+    y1 = y0 + 1
+
+    wa = ((x1 - x) * (y1 - y)).unsqueeze(1)
+    wb = ((x1 - x) * (y - y0)).unsqueeze(1)
+    wc = ((x - x0) * (y1 - y)).unsqueeze(1)
+    wd = ((x - x0) * (y - y0)).unsqueeze(1)
+
+    # Apply default for grid_sample function zero padding
+    im_padded = F.pad(im, pad=[1, 1, 1, 1], mode='constant', value=0)
+    padded_h = h + 2
+    padded_w = w + 2
+    # save points positions after padding
+    x0, x1, y0, y1 = x0 + 1, x1 + 1, y0 + 1, y1 + 1
+
+    # Clip coordinates to padded image size
+    x0 = paddle.where(x0 < 0, paddle.to_tensor(0), x0)
+    x0 = paddle.where(x0 > padded_w - 1, paddle.to_tensor(padded_w - 1), x0)
+    x1 = paddle.where(x1 < 0, paddle.to_tensor(0), x1)
+    x1 = paddle.where(x1 > padded_w - 1, paddle.to_tensor(padded_w - 1), x1)
+    y0 = paddle.where(y0 < 0, paddle.to_tensor(0), y0)
+    y0 = paddle.where(y0 > padded_h - 1, paddle.to_tensor(padded_h - 1), y0)
+    y1 = paddle.where(y1 < 0, paddle.to_tensor(0), y1)
+    y1 = paddle.where(y1 > padded_h - 1, paddle.to_tensor(padded_h - 1), y1)
+
+    im_padded = paddle.reshape(im_padded, [n, c, -1])
+
+    x0_y0 = paddle.expand((x0 + y0 * padded_w).unsqueeze(1), [-1, c, -1])
+    x0_y1 = paddle.expand((x0 + y1 * padded_w).unsqueeze(1), [-1, c, -1])
+    x1_y0 = paddle.expand((x1 + y0 * padded_w).unsqueeze(1), [-1, c, -1])
+    x1_y1 = paddle.expand((x1 + y1 * padded_w).unsqueeze(1), [-1, c, -1])
+
+    Ia = paddle.take_along_axis(im_padded, x0_y0, 2)
+    Ib = paddle.take_along_axis(im_padded, x0_y1, 2)
+    Ic = paddle.take_along_axis(im_padded, x1_y0, 2)
+    Id = paddle.take_along_axis(im_padded, x1_y1, 2)
+
+    return paddle.reshape(Ia * wa + Ib * wb + Ic * wc + Id * wd, [n, c, gh, gw])
 
 def grid_sample(input, grid, canvas=None):
     input.stop_gradient = False
@@ -36,7 +95,8 @@ def grid_sample(input, grid, canvas=None):
         input = input.cast(paddle.float32)
         grid = grid.cast(paddle.float32)
         is_fp16 = True
-    output = F.grid_sample(input, grid)
+    # output = F.grid_sample(input, grid)
+    output = bilinear_grid_sample(input, grid)
     if is_fp16:
         output = output.cast(data_type)
         grid = grid.cast(data_type)
@@ -48,7 +108,8 @@ def grid_sample(input, grid, canvas=None):
         if is_fp16:
             input_mask = input_mask.cast(paddle.float32)
             grid = grid.cast(paddle.float32)
-        output_mask = F.grid_sample(input_mask, grid)
+        # output_mask = F.grid_sample(input_mask, grid)
+        output_mask = bilinear_grid_sample(input_mask, grid)
         if is_fp16:
             output_mask = output_mask.cast(data_type)
         padded_output = output * output_mask + canvas * (1 - output_mask)
@@ -144,7 +205,7 @@ class TPSSpatialTransformer(nn.Layer):
 
         # register precomputed matrices
         self.inverse_kernel = inverse_kernel
-        self.padding_matrix = paddle.zeros(shape=[3, 2])
+        self.padding_matrix = paddle.zeros(shape=[1, 3, 2])
         self.target_coordinate_repr = target_coordinate_repr
         self.target_control_points = target_control_points
 
@@ -152,10 +213,11 @@ class TPSSpatialTransformer(nn.Layer):
         assert source_control_points.ndimension() == 3
         assert source_control_points.shape[1] == self.num_control_points
         assert source_control_points.shape[2] == 2
-        batch_size = paddle.shape(source_control_points)[0]
+        # batch_size = paddle.shape(source_control_points)[0]
 
-        padding_matrix = paddle.expand(
-            self.padding_matrix, shape=[batch_size, 3, 2])
+        # padding_matrix = paddle.expand(
+        #     self.padding_matrix, shape=[batch_size, 3, 2])
+        padding_matrix = self.padding_matrix
         Y = paddle.concat([
             source_control_points.astype(padding_matrix.dtype), padding_matrix
         ], 1)
